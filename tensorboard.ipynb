{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.__version__=1.10.1\n",
      "torchkeras.__version__=3.2.3\n"
     ]
    }
   ],
   "source": [
    "## 关于在pytorch中使用tensorboard的基础操作\n",
    "\n",
    "import torch \n",
    "import torchkeras\n",
    "## 先导包\n",
    "print(\"torch.__version__=\"+torch.__version__) \n",
    "print(\"torchkeras.__version__=\"+torchkeras.__version__) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、可视化模型结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "  (adaptive_pool): AdaptiveMaxPool2d(output_size=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear1): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (linear2): Linear(in_features=32, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchkeras \n",
    "\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3,out_channels=32,kernel_size = 3)\n",
    "        self.pool = nn.MaxPool2d(kernel_size = 2,stride = 2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32,out_channels=64,kernel_size = 5)\n",
    "        self.dropout = nn.Dropout2d(p = 0.1)\n",
    "        self.adaptive_pool = nn.AdaptiveMaxPool2d((1,1))\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear1 = nn.Linear(64,32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(32,1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.adaptive_pool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        y = self.linear2(x)\n",
    "        return y\n",
    "        \n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------\n",
      "Layer (type)                            Output Shape              Param #\n",
      "==========================================================================\n",
      "Conv2d-1                            [-1, 32, 30, 30]                  896\n",
      "MaxPool2d-2                         [-1, 32, 15, 15]                    0\n",
      "Conv2d-3                            [-1, 64, 11, 11]               51,264\n",
      "MaxPool2d-4                           [-1, 64, 5, 5]                    0\n",
      "Dropout2d-5                           [-1, 64, 5, 5]                    0\n",
      "AdaptiveMaxPool2d-6                   [-1, 64, 1, 1]                    0\n",
      "Flatten-7                                   [-1, 64]                    0\n",
      "Linear-8                                    [-1, 32]                2,080\n",
      "ReLU-9                                      [-1, 32]                    0\n",
      "Linear-10                                    [-1, 1]                   33\n",
      "==========================================================================\n",
      "Total params: 54,273\n",
      "Trainable params: 54,273\n",
      "Non-trainable params: 0\n",
      "--------------------------------------------------------------------------\n",
      "Input size (MB): 0.011719\n",
      "Forward/backward pass size (MB): 0.359627\n",
      "Params size (MB): 0.207035\n",
      "Estimated Total Size (MB): 0.578381\n",
      "--------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchkeras import summary \n",
    "summary(net,input_shape= (3,32,32));   # 利用torchkeras中的函数可以更清晰地总结模型结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 首先在Pytorch中指定一个目录创建一个torch.utils.tensorboard.SummaryWriter日志写入器\n",
    "# 这个写入器用来记录我们的数据日志变动，用于后面的可视化，同时保存所有的图表等数据\n",
    "writer = SummaryWriter('./data/tensorboard')\n",
    "writer.add_graph(net,input_to_model = torch.rand(1,3,32,32))\n",
    "# writer.add_graph用于可视化模型结构\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "#%tensorboard --logdir ./data/tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Known TensorBoard instances:\n",
      "  - port 6006: logdir ./data/tensorboard (started 1 day, 4:44:51 ago; pid 23976)\n"
     ]
    }
   ],
   "source": [
    "from tensorboard import notebook\n",
    "#查看启动的tensorboard程序\n",
    "notebook.list()    # 目前是没有任何启动"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 23976), started 1 day, 4:44:51 ago. (Use '!kill 23976' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-8b46d9caa27eb13d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-8b46d9caa27eb13d\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#启动tensorboard程序\n",
    "notebook.start(\"--logdir ./data/tensorboard\")\n",
    "#等价于在命令行中执行 tensorboard --logdir ./data/tensorboard\n",
    "#可以在浏览器中打开 http://localhost:6006/ 查看"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、可视化指标变化\n",
    "- **有时候在训练过程中，如果能够实时动态地查看loss和各种metric的变化曲线，那么无疑可以帮助我们更加直观地了解模型的训练情况。**\n",
    "\n",
    "- **注意，writer.add_scalar仅能对标量的值的变化进行可视化。因此它一般用于对loss和metric的变化进行可视化分析**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y= tensor(0.) ; x= tensor(1.0000)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "# f(x) = a*x**2 + b*x + c的最小值\n",
    "x = torch.tensor(0.0,requires_grad = True) # x需要被求导\n",
    "a = torch.tensor(1.0)\n",
    "b = torch.tensor(-2.0)\n",
    "c = torch.tensor(1.0)\n",
    "\n",
    "optimizer = torch.optim.SGD(params=[x],lr = 0.01)\n",
    "\n",
    "\n",
    "def f(x):\n",
    "    result = a*torch.pow(x,2) + b*x + c \n",
    "    return(result)\n",
    "\n",
    "for i in range(500):\n",
    "    optimizer.zero_grad()\n",
    "    y = f(x)\n",
    "    y.backward()\n",
    "    optimizer.step()\n",
    "    writer.add_scalar(\"x\",x.item(),i) #日志中记录x在第step i 的值\n",
    "    writer.add_scalar(\"y\",y.item(),i) #日志中记录y在第step i 的值\n",
    "\n",
    "writer.close()\n",
    "    \n",
    "print(\"y=\",f(x).data,\";\",\"x=\",x.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 三、可视化参数分布\n",
    "- **如果需要对模型的参数(一般非标量)在训练过程中的变化进行可视化，可以使用 writer.add_histogram**\n",
    "- **它能够观测张量值分布的直方图随训练步骤的变化趋势**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 创建正态分布的张量模拟参数矩阵\n",
    "def norm(mean,std):\n",
    "    t = std*torch.randn((100,20))+mean\n",
    "    return t\n",
    "\n",
    "for step,mean in enumerate(range(-10,10,1)):\n",
    "    w = norm(mean,1)\n",
    "    writer.add_histogram(\"w\",w, step)\n",
    "    writer.flush()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 四，可视化原始图像\n",
    "- **如果我们做图像相关的任务，也可以将原始的图片在tensorboard中进行可视化展示**\n",
    "\n",
    "- **如果只写入一张图片信息，可以使用writer.add_image**\n",
    "\n",
    "- **如果要写入多张图片信息，可以使用writer.add_images**\n",
    "\n",
    "- **也可以用 torchvision.utils.make_grid将多张图片拼成一张图片，然后用writer.add_image写入**\n",
    "\n",
    "- **注意，传入的是代表图片信息的Pytorch中的张量数据**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Couldn't find any class folder in ./data/FashionMNIST/raw/.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\EVER\\Desktop\\CodeSpace\\pytorch_demo\\tensorboard.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/EVER/Desktop/CodeSpace/pytorch_demo/tensorboard.ipynb#X24sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtransform_label\u001b[39m(x):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/EVER/Desktop/CodeSpace/pytorch_demo/tensorboard.ipynb#X24sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mtensor([x])\u001b[39m.\u001b[39mfloat()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/EVER/Desktop/CodeSpace/pytorch_demo/tensorboard.ipynb#X24sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m ds_train \u001b[39m=\u001b[39m datasets\u001b[39m.\u001b[39;49mImageFolder(\u001b[39m\"\u001b[39;49m\u001b[39m./data/FashionMNIST/raw/\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/EVER/Desktop/CodeSpace/pytorch_demo/tensorboard.ipynb#X24sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m             transform \u001b[39m=\u001b[39;49m transform_img,target_transform\u001b[39m=\u001b[39;49m transform_label)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/EVER/Desktop/CodeSpace/pytorch_demo/tensorboard.ipynb#X24sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m ds_val \u001b[39m=\u001b[39m datasets\u001b[39m.\u001b[39mImageFolder(\u001b[39m\"\u001b[39m\u001b[39m./data/cifar2/test/\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/EVER/Desktop/CodeSpace/pytorch_demo/tensorboard.ipynb#X24sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m             transform \u001b[39m=\u001b[39m transform_img,target_transform\u001b[39m=\u001b[39m transform_label)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/EVER/Desktop/CodeSpace/pytorch_demo/tensorboard.ipynb#X24sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mprint\u001b[39m(ds_train\u001b[39m.\u001b[39mclass_to_idx)\n",
      "File \u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\pytorch_gpu\\lib\\site-packages\\torchvision\\datasets\\folder.py:310\u001b[0m, in \u001b[0;36mImageFolder.__init__\u001b[1;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[0;32m    303\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[0;32m    304\u001b[0m         root: \u001b[39mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    308\u001b[0m         is_valid_file: Optional[Callable[[\u001b[39mstr\u001b[39m], \u001b[39mbool\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m ):\n\u001b[1;32m--> 310\u001b[0m     \u001b[39msuper\u001b[39;49m(ImageFolder, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(root, loader, IMG_EXTENSIONS \u001b[39mif\u001b[39;49;00m is_valid_file \u001b[39mis\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    311\u001b[0m                                       transform\u001b[39m=\u001b[39;49mtransform,\n\u001b[0;32m    312\u001b[0m                                       target_transform\u001b[39m=\u001b[39;49mtarget_transform,\n\u001b[0;32m    313\u001b[0m                                       is_valid_file\u001b[39m=\u001b[39;49mis_valid_file)\n\u001b[0;32m    314\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimgs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msamples\n",
      "File \u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\pytorch_gpu\\lib\\site-packages\\torchvision\\datasets\\folder.py:145\u001b[0m, in \u001b[0;36mDatasetFolder.__init__\u001b[1;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[0;32m    135\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[0;32m    136\u001b[0m         root: \u001b[39mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    141\u001b[0m         is_valid_file: Optional[Callable[[\u001b[39mstr\u001b[39m], \u001b[39mbool\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    142\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    143\u001b[0m     \u001b[39msuper\u001b[39m(DatasetFolder, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(root, transform\u001b[39m=\u001b[39mtransform,\n\u001b[0;32m    144\u001b[0m                                         target_transform\u001b[39m=\u001b[39mtarget_transform)\n\u001b[1;32m--> 145\u001b[0m     classes, class_to_idx \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfind_classes(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mroot)\n\u001b[0;32m    146\u001b[0m     samples \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_dataset(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mroot, class_to_idx, extensions, is_valid_file)\n\u001b[0;32m    148\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloader \u001b[39m=\u001b[39m loader\n",
      "File \u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\pytorch_gpu\\lib\\site-packages\\torchvision\\datasets\\folder.py:221\u001b[0m, in \u001b[0;36mDatasetFolder.find_classes\u001b[1;34m(self, directory)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfind_classes\u001b[39m(\u001b[39mself\u001b[39m, directory: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[List[\u001b[39mstr\u001b[39m], Dict[\u001b[39mstr\u001b[39m, \u001b[39mint\u001b[39m]]:\n\u001b[0;32m    195\u001b[0m     \u001b[39m\"\"\"Find the class folders in a dataset structured as follows::\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \n\u001b[0;32m    197\u001b[0m \u001b[39m        directory/\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[39m        (Tuple[List[str], Dict[str, int]]): List of all classes and dictionary mapping each class to an index.\u001b[39;00m\n\u001b[0;32m    220\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 221\u001b[0m     \u001b[39mreturn\u001b[39;00m find_classes(directory)\n",
      "File \u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\pytorch_gpu\\lib\\site-packages\\torchvision\\datasets\\folder.py:42\u001b[0m, in \u001b[0;36mfind_classes\u001b[1;34m(directory)\u001b[0m\n\u001b[0;32m     40\u001b[0m classes \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(entry\u001b[39m.\u001b[39mname \u001b[39mfor\u001b[39;00m entry \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mscandir(directory) \u001b[39mif\u001b[39;00m entry\u001b[39m.\u001b[39mis_dir())\n\u001b[0;32m     41\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m classes:\n\u001b[1;32m---> 42\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCouldn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt find any class folder in \u001b[39m\u001b[39m{\u001b[39;00mdirectory\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     44\u001b[0m class_to_idx \u001b[39m=\u001b[39m {cls_name: i \u001b[39mfor\u001b[39;00m i, cls_name \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(classes)}\n\u001b[0;32m     45\u001b[0m \u001b[39mreturn\u001b[39;00m classes, class_to_idx\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: Couldn't find any class folder in ./data/FashionMNIST/raw/."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torchvision import transforms as T,datasets \n",
    "\n",
    "\n",
    "transform_img = T.Compose(\n",
    "    [T.ToTensor()])\n",
    "\n",
    "def transform_label(x):\n",
    "    return torch.tensor([x]).float()\n",
    "\n",
    "ds_train = datasets.ImageFolder(\"./data/cifar2/train/\",\n",
    "            transform = transform_img,target_transform= transform_label)\n",
    "ds_val = datasets.ImageFolder(\"./data/cifar2/test/\",\n",
    "            transform = transform_img,target_transform= transform_label)\n",
    "\n",
    "print(ds_train.class_to_idx)\n",
    "\n",
    "dl_train = DataLoader(ds_train,batch_size = 50,shuffle = True)\n",
    "dl_val = DataLoader(ds_val,batch_size = 50,shuffle = True)\n",
    "\n",
    "images,labels = next(iter(dl_train))\n",
    "\n",
    "# 仅查看一张图片\n",
    "writer = SummaryWriter('./data/tensorboard')\n",
    "writer.add_image('images[0]', images[0])\n",
    "writer.close()\n",
    "\n",
    "# 将多张图片拼接成一张图片，中间用黑色网格分割\n",
    "writer = SummaryWriter('./data/tensorboard')\n",
    "# create grid of images\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "writer.add_image('image_grid', img_grid)\n",
    "writer.close()\n",
    "\n",
    "# 将多张图片直接写入\n",
    "writer = SummaryWriter('./data/tensorboard')\n",
    "writer.add_images(\"images\",images,global_step = 0)\n",
    "writer.close()\n",
    "\n",
    "\n",
    "### 这个地方只把代码写出来模拟一下过程，没有实际数据就不运行了"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('pytorch_gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2679cf41411127fad6b4c826b494c1155011be46cd2606cdd62e601481ef25df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
